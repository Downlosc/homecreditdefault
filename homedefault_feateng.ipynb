{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca to reduce feature space? collinearity? correlations? noisy features removal? Tikhonov regularization \n",
    "# train model with boost library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove collinear features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization is the process of introducing additional information in order to solve ill-posed problems or prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load final train\n",
    "train = pd.read_csv('../../data/trainjoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the upper triangle of the Pearson correlation coefficient matrix. The pearson coefficient is computed between every pair of features\n",
    "corrMatrix = train.drop('TARGET', axis=1).corr().abs()\n",
    "tableCorrelations = corrMatrix.where(np.triu(np.ones(corrMatrix.shape), k=1).astype(np.bool)).stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Pearson correlation coefficients: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient. between every variable and the #target using th\n",
    "#\n",
    "#correlations = train.corr()['TARGET'].sort_values()\n",
    "#\n",
    "#print('Most Positive Correlations:\\n', correlations.tail(10))\n",
    "#print('Most Negative Correlations:', correlations.head(10))\n",
    "\n",
    "#Explanation: since the DAYS_BIRTH feature increases negatively, and the correlation is positive, it means that as the client gets older he will be less likely to default. Moreover, among the top ones we have features as EXT_SOURCE_1/3, EDUCATION TYPE .. . However, none of the features seem to be strongly correlated w/ the target w/ respect to Evans (1996) general interpretatoins (http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf). Indeed having an abs value Pearson coefficient between .00-.19 is considered as \"very week\" correlation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize w/ a density plot how the younger clients tend to default more likely\n",
    "#plt.figure(figsize = (10, 8))\n",
    "#\n",
    "## KDE plot of loans that were repaid on time\n",
    "#sns.kdeplot(train.loc[train['TARGET'] == 0, 'DAYS_BIRTH'] / -365, label = 'target == 0')\n",
    "#\n",
    "## KDE plot of loans which were not repaid on time\n",
    "#sns.kdeplot(train.loc[train['TARGET'] == 1, 'DAYS_BIRTH'] / -365, label = 'target == 1')\n",
    "## Labeling of plot\n",
    "#plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');"
   ]
  }
 ]
}