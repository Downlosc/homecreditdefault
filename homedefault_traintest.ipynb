{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/cs/master/fds/project/repo/homecreditdefault\n"
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import first data\n",
    "train = pd.read_csv(\"../../data/application_train.csv\")\n",
    "test = pd.read_csv(\"../../data/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration Basics: check the balaceness of the train set\n",
    "nodef= train[train['TARGET']==0]\n",
    "print(str(len(nodef)/307511))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes\n",
    "#shows a lot of categorical features which we want to transform into numerical features\n",
    "#binary categorical -> 0,1 \n",
    "#what about more catoegories? Giving more values ie 0,1,2,3,... would make the model attribute them different importances whereas they are just different cateogries! Thus replace them with different features one for each category"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and print all the categorical columns\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        print(col)\n",
    "        print(train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def onehot_binenc(df):\n",
    "\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    #find feaures w two categories and transform them either to 0 or 1\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object and len(df[col].unique()) <= 2 :\n",
    "            le.fit(df[col])\n",
    "            df[col]=le.transform(df[col])\n",
    "    #one hot encoding of the remaining k-categorical features, w/ k>2\n",
    "    return pd.get_dummies(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = onehot_binenc(train)\n",
    "test = onehot_binenc(test)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape\n",
    "#We remain w/ more columns in the trainset. This is due to the fact that there were some categorical variables w/ categories only present in the train set but not in the test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need the same set of columns in both train and test set\n",
    "target = train['TARGET']\n",
    "\n",
    "#Align the training and testing data, keep only columns present in both dataframes\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "#Add the target back in\n",
    "train['TARGET'] = target\n",
    "\n",
    "print('Training Features shape: ', train.shape)\n",
    "print('Testing Features shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "nulls= train.isnull().sum()\n",
    "nulls= nulls[nulls > 0]\n",
    "\n",
    "#how many null values are indeed present?\n",
    "nulls / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as for the previous cell, there a bunch of features with missing values, then we want to substitute those missing values with a certain strategy, e.g. by replacing w/ the median \n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy = \"median\")\n",
    "\n",
    "imputer.fit(train)\n",
    "train.loc[:] = imputer.transform(train)\n",
    "\n",
    "imputer.fit(test)\n",
    "test.loc[:] = imputer.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "nulls= train.isnull().sum()\n",
    "nulls= nulls[nulls > 0]\n",
    "\n",
    "#how many null values are now present?\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "nulls= test.isnull().sum()\n",
    "nulls= nulls[nulls > 0]\n",
    "\n",
    "#how many null values are now present?\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 Feature exploration ###\n",
    "\n",
    "from featexp import get_univariate_plots\n",
    "\n",
    "# Plots drawn for all features if nothing is passed in feature_list parameter.\n",
    "get_univariate_plots(data=train, target_col='TARGET', \n",
    "                     features_list=['DAYS_BIRTH'], bins=10)\n",
    "# RESULT: The more they are young, the more the tend not to pay! From the article: \" The plot tells us that customers with high negative values for DAYS_BIRTH (higher age) have lower default rates\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. Identifying noisy features ####\n",
    "\n",
    "#Build a validation set\n",
    "msk = np.random.rand(len(train)) < 0.6\n",
    "trainset = train[msk].astype(np.float32)\n",
    "validationset = train[~msk].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_univariate_plots(data=trainset, target_col='TARGET', data_test=validationset, features_list=['DAYS_EMPLOYED'], bins=10)\n",
    "\n",
    "#RESULT: High correlation between the trend in validation and train set, therefore should not be a noisy feature!\n",
    "# What if the trend changes a lot tho? Well it might be true then that this its a symptom of noisyness nevertheless the considered bins migh differ \n",
    "# a lot in other features giving us a different trends in default rates.\n",
    "# What should we do then? Cross Validation!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featexp import get_trend_stats\n",
    "stats = get_trend_stats(data=trainset, target_col='TARGET', data_test=validationset)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate to have more representative trend_correlations \n",
    "#10-Folds\n",
    "\n",
    "total_trend_correlations=stats['Trend_correlation']\n",
    "for i in range(0,9):\n",
    "    msk = np.random.rand(len(train)) < 0.6\n",
    "    trainset = train[msk].astype(np.float32)\n",
    "    validationset = train[~msk].astype(np.float32)\n",
    "    \n",
    "    ith_stats = get_trend_stats(data=trainset, target_col='TARGET', data_test=validationset)\n",
    "    ith_tc = ith_stats['Trend_correlation']\n",
    "    \n",
    "    total_trend_correlations += ith_tc\n",
    "\n",
    "averaged_trend_correlations = total_trend_correlations / 10"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_trend_correlations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop from our original train set all the columns we deduced to label as noisy w/ respect to the trend_correlation average and by using a treshold of 0.9.\n",
    "#Meaning that, we consider as noisy features all the features which have averaged_trend_correlations smaller than 0.90\n",
    "\n",
    "stats['Trend_correlation']=averaged_trend_correlations\n",
    "\n",
    "#We also want to save SK_ID_CURR as it will be useful later\n",
    "noisy_f= stats.loc[(stats['Feature'] != 'SK_ID_CURR') & (stats['Trend_correlation'] < 0.80)]['Feature'].reset_index()\n",
    "\n",
    "train=train.drop(noisy_f['Feature'], axis=1)\n",
    "test=test.drop(noisy_f['Feature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3. Anomalies ####\n",
    "#Look around for anomalies by using the describe method\n",
    "(train['DAYS_BIRTH'] / -365).describe()\n",
    "#N: Those ages look reasonable. There are no outliers for the age on either the high or low end.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How about the days of employment?\n",
    "train['DAYS_EMPLOYED'].describe()\n",
    "#N: Big outliers! Describe shows a guy who apparently has been working for 1k years :S (plus being a positive number)\n",
    "#   Moreover, the mean is 174 years still unreal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DAYS_EMPLOYED per years\n",
    "train['DAYS_EMPLOYED'].plot.hist(title = 'Years Employment Histogram')\n",
    "plt.xlabel('Days Employment')\n",
    "\n",
    "# The plot shows a clearly bipartite distribution. Call anomalies the ones around 1k years and healthy the ones around 0\n",
    "# Increase now the number of bits to actually see if such a distribution has bigger granularity\n",
    "train['DAYS_EMPLOYED'].plot.hist(title = 'Years Employment Histogram', bins=150)\n",
    "plt.xlabel('Days Employment')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The previous plot gives us an insight: the anomalies appear to have all exactly 1k years of employment, lets check it analitically\n",
    "anomalies = train[train['DAYS_EMPLOYED'] == 365243]\n",
    "healthy = train[(train['DAYS_EMPLOYED'] >= -17912) & (train['DAYS_EMPLOYED'] <= 0)]\n",
    "print(\"Number of anomalies with 1k years of work: %d\" % len(anomalies))\n",
    "print(\"Number of healty records: %d\" % len(healthy))\n",
    "print(\"Is there anyone missing?: %d\" % (307511 - (len(healthy)+len(anomalies))) )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have understood that all the anomalies lie in exactly the same outlier, we want to see if they also have some correlation with the ratio of defaults\n",
    "print('The non-anomalies default on %0.2f%% of loans' % (100 * healthy['TARGET'].mean()))\n",
    "print('The anomalies default on %0.2f%% of loans' % (100 * anomalies['TARGET'].mean()))\n",
    "#With respect to the default-ratio of the healthy, the anomalies have a lower default rate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Therefore it seems like there is some correlation between the loans that was wrongly recorded (employment - wise) and the rate of defaults. Like they encode  hidden feature/s. We then might want to tell this to the classifier by explicitly making a new \"employment-anomaly\" feature. However, we also don't want to loose the idea of days of employment. That's why we will set a new common value to all the anomalies, such as the median of the healthy.\n",
    "\n",
    "#Create an anomalous flag column\n",
    "train['DAYS_EMPLOYED_ANOM'] = train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "#Replace the anomalous values with median\n",
    "train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "train['DAYS_EMPLOYED'].fillna(train['DAYS_EMPLOYED'].median(), inplace=True)\n",
    "\n",
    "#Note that the test follow the same distribution between anomaly and healthy DAYS_EMPLOYMENT. Therefore to the same preprocessing to the testset\n",
    "test['DAYS_EMPLOYED_ANOM'] = test[\"DAYS_EMPLOYED\"] == 365243\n",
    "test['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "test['DAYS_EMPLOYED'].fillna(test['DAYS_EMPLOYED'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_EMPLOYED_ANOM'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the remaining columns to see if there are any salient feature to be inspected for anomalies\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "display(train.describe())\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After and in-depth check of all the remaining features we did not find any substantial indication for anomalies. Plus, most of the remaining features are normalized hence difficult to interpret"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save what is done so far\n",
    "train.to_csv('../../data/train.csv', index=False)\n",
    "test.to_csv('../../data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to the merge phase"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}