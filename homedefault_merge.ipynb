{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shrink down as much as we can the size of the dataframes.\n",
    "#Note that every numerical value lies within the range indexed with a float/int of 32 bits\n",
    "#Moreover is wise to convert every object feature into a category one, especially if the number of unique values is far from the number of rows\n",
    "\n",
    "import sys\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    # Iterate through each column\n",
    "    for c in df:\n",
    "        \n",
    "        # Convert ids and booleans to integers\n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "            \n",
    "        # Convert objects to category\n",
    "        elif (df[c].dtype == 'object') and (df[c].nunique() < df.shape[0]):\n",
    "            df[c] = df[c].astype('category')\n",
    "        \n",
    "        # Booleans mapped to integers\n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        \n",
    "        # Float64 to float32\n",
    "        elif df[c].dtype == float:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "            \n",
    "        # Int64 to int32\n",
    "        elif df[c].dtype == int:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load preprocessed train and convert types and sanity check\n",
    "train=pd.read_csv('../../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.46 gb.\nNew Memory Usage: 0.21 gb.\n"
    }
   ],
   "source": [
    "train=convert_types(train, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 307511 entries, 0 to 307510\nData columns (total 187 columns):\nSK_ID_CURR                                           int32\nNAME_CONTRACT_TYPE                                   float32\nFLAG_OWN_CAR                                         float32\nFLAG_OWN_REALTY                                      bool\nCNT_CHILDREN                                         float32\nAMT_INCOME_TOTAL                                     float32\nAMT_CREDIT                                           float32\nAMT_ANNUITY                                          float32\nAMT_GOODS_PRICE                                      float32\nREGION_POPULATION_RELATIVE                           float32\nDAYS_BIRTH                                           float32\nDAYS_EMPLOYED                                        float32\nDAYS_REGISTRATION                                    float32\nDAYS_ID_PUBLISH                                      float32\nOWN_CAR_AGE                                          float32\nFLAG_EMP_PHONE                                       bool\nFLAG_WORK_PHONE                                      float32\nFLAG_PHONE                                           bool\nCNT_FAM_MEMBERS                                      float32\nREGION_RATING_CLIENT                                 float32\nREGION_RATING_CLIENT_W_CITY                          float32\nHOUR_APPR_PROCESS_START                              float32\nREG_REGION_NOT_LIVE_REGION                           float32\nREG_REGION_NOT_WORK_REGION                           float32\nLIVE_REGION_NOT_WORK_REGION                          float32\nREG_CITY_NOT_LIVE_CITY                               float32\nREG_CITY_NOT_WORK_CITY                               float32\nLIVE_CITY_NOT_WORK_CITY                              float32\nEXT_SOURCE_1                                         float32\nEXT_SOURCE_2                                         float32\nEXT_SOURCE_3                                         float32\nAPARTMENTS_AVG                                       float32\nBASEMENTAREA_AVG                                     float32\nYEARS_BEGINEXPLUATATION_AVG                          float32\nYEARS_BUILD_AVG                                      float32\nCOMMONAREA_AVG                                       float32\nELEVATORS_AVG                                        float32\nENTRANCES_AVG                                        float32\nFLOORSMAX_AVG                                        float32\nFLOORSMIN_AVG                                        float32\nLIVINGAPARTMENTS_AVG                                 float32\nLIVINGAREA_AVG                                       float32\nNONLIVINGAPARTMENTS_AVG                              float32\nNONLIVINGAREA_AVG                                    float32\nAPARTMENTS_MODE                                      float32\nBASEMENTAREA_MODE                                    float32\nYEARS_BEGINEXPLUATATION_MODE                         float32\nYEARS_BUILD_MODE                                     float32\nCOMMONAREA_MODE                                      float32\nELEVATORS_MODE                                       float32\nENTRANCES_MODE                                       float32\nFLOORSMAX_MODE                                       float32\nFLOORSMIN_MODE                                       float32\nLIVINGAPARTMENTS_MODE                                float32\nLIVINGAREA_MODE                                      float32\nNONLIVINGAPARTMENTS_MODE                             float32\nNONLIVINGAREA_MODE                                   float32\nAPARTMENTS_MEDI                                      float32\nBASEMENTAREA_MEDI                                    float32\nYEARS_BEGINEXPLUATATION_MEDI                         float32\nYEARS_BUILD_MEDI                                     float32\nCOMMONAREA_MEDI                                      float32\nELEVATORS_MEDI                                       float32\nENTRANCES_MEDI                                       float32\nFLOORSMAX_MEDI                                       float32\nFLOORSMIN_MEDI                                       float32\nLIVINGAPARTMENTS_MEDI                                float32\nLIVINGAREA_MEDI                                      float32\nNONLIVINGAPARTMENTS_MEDI                             float32\nTOTALAREA_MODE                                       float32\nDEF_30_CNT_SOCIAL_CIRCLE                             float32\nDEF_60_CNT_SOCIAL_CIRCLE                             float32\nDAYS_LAST_PHONE_CHANGE                               float32\nFLAG_DOCUMENT_3                                      bool\nFLAG_DOCUMENT_4                                      float32\nFLAG_DOCUMENT_6                                      float32\nFLAG_DOCUMENT_8                                      float32\nFLAG_DOCUMENT_9                                      float32\nFLAG_DOCUMENT_10                                     float32\nFLAG_DOCUMENT_11                                     float32\nFLAG_DOCUMENT_13                                     float32\nFLAG_DOCUMENT_14                                     float32\nFLAG_DOCUMENT_15                                     float32\nFLAG_DOCUMENT_16                                     float32\nFLAG_DOCUMENT_17                                     float32\nFLAG_DOCUMENT_18                                     float32\nFLAG_DOCUMENT_21                                     float32\nAMT_REQ_CREDIT_BUREAU_DAY                            float32\nAMT_REQ_CREDIT_BUREAU_WEEK                           float32\nAMT_REQ_CREDIT_BUREAU_MON                            float32\nAMT_REQ_CREDIT_BUREAU_QRT                            float32\nAMT_REQ_CREDIT_BUREAU_YEAR                           float32\nNAME_TYPE_SUITE_Children                             float32\nNAME_TYPE_SUITE_Family                               float32\nNAME_TYPE_SUITE_Other_B                              float32\nNAME_TYPE_SUITE_Unaccompanied                        bool\nNAME_INCOME_TYPE_Businessman                         float32\nNAME_INCOME_TYPE_Commercial associate                float32\nNAME_INCOME_TYPE_Pensioner                           float32\nNAME_INCOME_TYPE_State servant                       float32\nNAME_INCOME_TYPE_Student                             float32\nNAME_INCOME_TYPE_Unemployed                          float32\nNAME_INCOME_TYPE_Working                             bool\nNAME_EDUCATION_TYPE_Academic degree                  float32\nNAME_EDUCATION_TYPE_Higher education                 float32\nNAME_EDUCATION_TYPE_Lower secondary                  float32\nNAME_EDUCATION_TYPE_Secondary / secondary special    bool\nNAME_FAMILY_STATUS_Civil marriage                    float32\nNAME_FAMILY_STATUS_Married                           float32\nNAME_FAMILY_STATUS_Single / not married              bool\nNAME_FAMILY_STATUS_Widow                             float32\nNAME_HOUSING_TYPE_House / apartment                  bool\nNAME_HOUSING_TYPE_Municipal apartment                float32\nNAME_HOUSING_TYPE_Office apartment                   float32\nNAME_HOUSING_TYPE_Rented apartment                   float32\nNAME_HOUSING_TYPE_With parents                       float32\nOCCUPATION_TYPE_Accountants                          float32\nOCCUPATION_TYPE_Cleaning staff                       float32\nOCCUPATION_TYPE_Cooking staff                        float32\nOCCUPATION_TYPE_Core staff                           float32\nOCCUPATION_TYPE_Drivers                              float32\nOCCUPATION_TYPE_HR staff                             float32\nOCCUPATION_TYPE_High skill tech staff                float32\nOCCUPATION_TYPE_IT staff                             float32\nOCCUPATION_TYPE_Laborers                             bool\nOCCUPATION_TYPE_Low-skill Laborers                   float32\nOCCUPATION_TYPE_Managers                             float32\nOCCUPATION_TYPE_Medicine staff                       float32\nOCCUPATION_TYPE_Private service staff                float32\nOCCUPATION_TYPE_Sales staff                          float32\nOCCUPATION_TYPE_Secretaries                          float32\nOCCUPATION_TYPE_Security staff                       float32\nOCCUPATION_TYPE_Waiters/barmen staff                 float32\nWEEKDAY_APPR_PROCESS_START_MONDAY                    float32\nWEEKDAY_APPR_PROCESS_START_TUESDAY                   float32\nORGANIZATION_TYPE_Agriculture                        float32\nORGANIZATION_TYPE_Bank                               float32\nORGANIZATION_TYPE_Business Entity Type 2             float32\nORGANIZATION_TYPE_Business Entity Type 3             bool\nORGANIZATION_TYPE_Cleaning                           float32\nORGANIZATION_TYPE_Construction                       float32\nORGANIZATION_TYPE_Culture                            float32\nORGANIZATION_TYPE_Government                         float32\nORGANIZATION_TYPE_Hotel                              float32\nORGANIZATION_TYPE_Industry: type 1                   float32\nORGANIZATION_TYPE_Industry: type 12                  float32\nORGANIZATION_TYPE_Industry: type 3                   float32\nORGANIZATION_TYPE_Industry: type 4                   float32\nORGANIZATION_TYPE_Industry: type 9                   float32\nORGANIZATION_TYPE_Insurance                          float32\nORGANIZATION_TYPE_Kindergarten                       float32\nORGANIZATION_TYPE_Medicine                           float32\nORGANIZATION_TYPE_Military                           float32\nORGANIZATION_TYPE_Other                              float32\nORGANIZATION_TYPE_Police                             float32\nORGANIZATION_TYPE_Restaurant                         float32\nORGANIZATION_TYPE_School                             float32\nORGANIZATION_TYPE_Security                           float32\nORGANIZATION_TYPE_Security Ministries                float32\nORGANIZATION_TYPE_Self-employed                      float32\nORGANIZATION_TYPE_Services                           float32\nORGANIZATION_TYPE_Trade: type 2                      float32\nORGANIZATION_TYPE_Trade: type 3                      float32\nORGANIZATION_TYPE_Trade: type 4                      float32\nORGANIZATION_TYPE_Trade: type 6                      float32\nORGANIZATION_TYPE_Trade: type 7                      float32\nORGANIZATION_TYPE_Transport: type 1                  float32\nORGANIZATION_TYPE_Transport: type 3                  float32\nORGANIZATION_TYPE_Transport: type 4                  float32\nORGANIZATION_TYPE_University                         float32\nORGANIZATION_TYPE_XNA                                float32\nFONDKAPREMONT_MODE_not specified                     float32\nFONDKAPREMONT_MODE_org spec account                  float32\nFONDKAPREMONT_MODE_reg oper account                  bool\nFONDKAPREMONT_MODE_reg oper spec account             float32\nHOUSETYPE_MODE_block of flats                        bool\nHOUSETYPE_MODE_specific housing                      float32\nWALLSMATERIAL_MODE_Block                             float32\nWALLSMATERIAL_MODE_Mixed                             float32\nWALLSMATERIAL_MODE_Monolithic                        float32\nWALLSMATERIAL_MODE_Panel                             float32\nWALLSMATERIAL_MODE_Stone, brick                      bool\nWALLSMATERIAL_MODE_Wooden                            float32\nEMERGENCYSTATE_MODE_No                               bool\nEMERGENCYSTATE_MODE_Yes                              float32\nTARGET                                               bool\nDAYS_EMPLOYED_ANOM                                   bool\ndtypes: bool(17), float32(169), int32(1)\nmemory usage: 204.4 MB\n"
    }
   ],
   "source": [
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOTIVATION: We are not loan's domain experts, thus ... (see notes on ipad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def onehot_binenc(df, type = 'object'):\n",
    "    \"\"\" dtype should be 'object' or 'category' depending on the dataframe being converted or not \"\"\"\n",
    "    \n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    #counter for binary categorical features\n",
    "    bcount = 0\n",
    "    #find feaures w two categories and transform them either to 0 or 1\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == type and len(df[col].unique()) <= 2 :\n",
    "            le.fit(df[col])\n",
    "            df[col]=le.transform(df[col])\n",
    "            bcount+=1\n",
    "    \n",
    "    #one hot encoding of the remaining k-categorical features, w/ k>2. If there's any\n",
    "    if (bcount < df.shape[1]):\n",
    "        df = pd.get_dummies(df)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4. Merging ####\n",
    "#define a function to left join two datasets by handling separately numerical features and categorical ones\n",
    "def join_w_stats(id, df1, df2, df2_name):\n",
    "    \"\"\" Merge two dataframes (df1 and df2) by grouping df2 on id and computing the following statistics:\n",
    "            i) Mean, Min and Max and sum for numeric features\n",
    "            ii) Mean for categorical features \n",
    "        In this way, indeed, we hope to preserve the essence of the information stored in each feature after groub by\"\"\"\n",
    "\n",
    "    #drop from df2 the id column since it is not necessary and won't be used anymore\n",
    "    df2 = df2.drop([col for col in df2.columns if col.startswith('SK_ID') and col != id], axis=1)\n",
    "    newcolumns = []\n",
    "    \n",
    "    \n",
    "    #compute statistics for numerical feats, if there's any\n",
    "    numericaldf2 = df2.select_dtypes(include='number')\n",
    "    count_numericalcols = len(numericaldf2.columns)\n",
    "    if count_numericalcols > 1: #1 is the id\n",
    "        \n",
    "        numericaldf2[id] = df2[id]\n",
    "        numstatsdf2 = numericaldf2.groupby(id).agg(['mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "        #create new columns names for each numerical feature_stat\n",
    "        for col in numstatsdf2.columns.levels[0]: \n",
    "            if col != id:\n",
    "                #loop through every subcolumn name\n",
    "                for stat in numstatsdf2.columns.levels[1][:-1]:\n",
    "                    newcolumns.append('%s_%s_%s' % (df2_name, col, stat))\n",
    "\n",
    "   \n",
    "    #compute mean for categorical feats, if there's any\n",
    "    categorical = False\n",
    "    if (len(df2.columns) - count_numericalcols) > 0:\n",
    "        categoricaldf2 = df2.select_dtypes(include='category')\n",
    "        categorical = True\n",
    "        onehotdf2 = onehot_binenc(categoricaldf2, 'category')\n",
    "        onehotdf2[id] = df2[id]\n",
    "        onehotstatsdf2 = onehotdf2.groupby(id).agg(['mean']).reset_index()\n",
    "    \n",
    "        #create new columns names for each categorical feature_stat\n",
    "        for col in onehotstatsdf2.columns.levels[0]: \n",
    "            if col != id:\n",
    "                #for categoricals the only subcolumn is the mean\n",
    "                newcolumns.append('%s_%s_mean' % (df2_name, col))\n",
    "\n",
    "    # df2 no longer needed. Free memory\n",
    "    gc.enable()\n",
    "    del df2\n",
    "    gc.collect()\n",
    "\n",
    "    #merge both numerical and categorical (if there is any) statistics dsets grouped by id. And then with df1\n",
    "    if categorical == True:\n",
    "        numstatsdf2 = numstatsdf2.join(onehotstatsdf2.set_index(id), on=id)\n",
    "        \n",
    "    #add new columns names    \n",
    "    numstatsdf2.columns = [id]+newcolumns \n",
    "    #left join on id df1 w/ merged statistics of df2\n",
    "    df1joindf2 = df1.join(numstatsdf2.set_index(id), on=id)\n",
    "\n",
    "\n",
    "    # df1 no longer needed. Free memory\n",
    "    gc.enable()\n",
    "    del df1\n",
    "    gc.collect()\n",
    "\n",
    "    # some cast might happen during merge and groupby, thus convert again\n",
    "    convert_types(df1joindf2)\n",
    "\n",
    "    return df1joindf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousApplication = pd.read_csv('../../data/previous_application.csv')\n",
    "installmentsPayments = pd.read_csv('../../data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.49 gb.\nNew Memory Usage: 0.16 gb.\n"
    }
   ],
   "source": [
    "previousApplication = convert_types(previousApplication, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.87 gb.\nNew Memory Usage: 0.44 gb.\n"
    }
   ],
   "source": [
    "installmentsPayments = convert_types(installmentsPayments, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousJOINinstallments = join_w_stats('SK_ID_PREV', previousApplication, installmentsPayments, 'installments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashBalance = pd.read_csv('../../data/POS_CASH_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.64 gb.\nNew Memory Usage: 0.29 gb.\n"
    }
   ],
   "source": [
    "cashBalance = convert_types(cashBalance, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    }
   ],
   "source": [
    "previousJOINcashBalanceJOINinstallments = join_w_stats('SK_ID_PREV', previousJOINinstallments, cashBalance, 'cash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditCardBalance = pd.read_csv('../../data/credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.71 gb.\nNew Memory Usage: 0.34 gb.\n"
    }
   ],
   "source": [
    "creditCardBalance = convert_types(creditCardBalance, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    }
   ],
   "source": [
    "previousJOINcashBalanceJOINinstallmentsJOINcreditCardBalance = join_w_stats('SK_ID_PREV', previousJOINcashBalanceJOINinstallments, creditCardBalance, 'creditcard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#every time we are saving a csv, dtypes are lost by default. Define the following read and write function to preserve converted types in the first row to avoid another conversion after every loading.\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def to_csv(df, path):\n",
    "    \n",
    "    dtypes = df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "    jtypes = json.dumps(dtypes)\n",
    "\n",
    "    fileName = os.path.splitext(path)\n",
    "\n",
    "    # save df as usual along with a json representation of the dictionary\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "    f = open(fileName[0]+'Types',\"w\")\n",
    "    f.write(jtypes)\n",
    "    f.close()\n",
    "\n",
    "    # free memory\n",
    "    gc.enable()\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "def read_csv(path):\n",
    "    \n",
    "    fileName = os.path.splitext(path)\n",
    "    \n",
    "    jtypes = json.load(open(fileName[0]+'Types'))\n",
    "    \n",
    "    return pd.read_csv(path, dtype=jtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  del sys.path[0]\n"
    }
   ],
   "source": [
    "trainJOINprev = join_w_stats('SK_ID_CURR', train, previousJOINcashBalanceJOINinstallmentsJOINcreditCardBalance, 'prev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store joined previous loans dara since it will be merged to test as well\n",
    "to_csv(previousJOINcashBalanceJOINinstallmentsJOINcreditCardBalance, '../../data/previousJoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all features with more than 60% of N.a.N\n",
    "def remove_missing_columns(df, threshold = 60):\n",
    "    # Calculate missing stats for df (remember to calculate a percent!)\n",
    "    df_miss = pd.DataFrame(df.isnull().sum())\n",
    "    df_miss['percent'] = 100 * df_miss[0] / len(df)\n",
    "    \n",
    "    \n",
    "    # list of missing columns for df\n",
    "    missing_df_columns = list(df_miss.index[df_miss['percent'] > threshold])\n",
    "    \n",
    "    # Print information\n",
    "    print('There are %d columns with greater than %d%% missing values.' % (len(missing_df_columns), threshold))\n",
    "    \n",
    "    # Drop the missing columns and return\n",
    "    df = df.drop(columns = missing_df_columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are 267 columns with greater than 60% missing values.\n"
    }
   ],
   "source": [
    "#drop all the new computed features that we consider no-influent from trainJOINprev\n",
    "trainJOINprev = remove_missing_columns(trainJOINprev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureauBalance = pd.read_csv('../../data/bureau_balance.csv')\n",
    "bureau = pd.read_csv('../../data/bureau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.66 gb.\nNew Memory Usage: 0.25 gb.\nOriginal Memory Usage: 0.23 gb.\nNew Memory Usage: 0.1 gb.\n"
    }
   ],
   "source": [
    "bureauBalance = convert_types(bureauBalance, print_info=True)\n",
    "bureau = convert_types(bureau, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    }
   ],
   "source": [
    "bureauJOINbureauBalance = join_w_stats('SK_ID_BUREAU', bureau, bureauBalance, 'bureauBalance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    }
   ],
   "source": [
    "trainJoined = join_w_stats('SK_ID_CURR', trainJOINprev, bureauJOINbureauBalance, 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are 39 columns with greater than 60% missing values.\n"
    }
   ],
   "source": [
    "trainJoined = remove_missing_columns(trainJoined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(bureauJOINbureauBalance, '../../data/bureauJoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the final train\n",
    "to_csv(trainJoined, '../../data/trainjoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original Memory Usage: 0.07 gb.\nNew Memory Usage: 0.03 gb.\n"
    }
   ],
   "source": [
    "## apply the same logic to the test ##\n",
    "test = pd.read_csv('../../data/test.csv')\n",
    "test = convert_types(test, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously stored, read infering the right types\n",
    "prevJoined = read_csv('../../data/previousJoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  del sys.path[0]\n"
    }
   ],
   "source": [
    "testJOINprev = join_w_stats('SK_ID_CURR', test, prevJoined, 'prev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are 267 columns with greater than 60% missing values.\n"
    }
   ],
   "source": [
    "testJOINprev = remove_missing_columns(testJOINprev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureauJOINbureauBalance = read_csv('../../data/bureauJoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/arbiterelegantiae/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
    }
   ],
   "source": [
    "testJoined = join_w_stats('SK_ID_CURR', testJOINprev, bureauJOINbureauBalance, 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are 0 columns with greater than 60% missing values.\n"
    }
   ],
   "source": [
    "testJoined = remove_missing_columns(testJoined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainJoined = read_csv('../../data/trainjoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "774\n812\n"
    }
   ],
   "source": [
    "## it seems like there were more sparse features in train than in test that were removed, this is reasonable due to the larger ids in train\n",
    "print(len(trainJoined.columns))\n",
    "print(len(testJoined.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(307511, 774)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to align as we did in homedefault_traintest\n",
    "\n",
    "target = trainJoined['TARGET']\n",
    "\n",
    "#Align the training and testing data, keep only columns present in both dataframes\n",
    "trainJoined, testJoined = trainJoined.align(testJoined, join = 'inner', axis = 1)\n",
    "\n",
    "#Add the target back in\n",
    "trainJoined['TARGET'] = target\n",
    "\n",
    "trainJoined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(48744, 773)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testJoined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(trainJoined, '../../data/trainjoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(testJoined, '../../data/testjoined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to the feat engineering phase"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}